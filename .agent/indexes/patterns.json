{
  "patterns": [
    {
      "id": "auth_check_standard",
      "name": "Standard Auth Check Pattern",
      "category": "security",
      "language": "python",
      "description": "Standard pattern for verifying user identity and ownership in FastAPI routes",
      "code": "@router.get('/twins/{twin_id}')\nasync def get_twin(\n    twin_id: str,\n    user: dict = Depends(get_current_user)\n):\n    verify_owner(user, twin_id)\n    # ... rest of logic",
      "usage_count": 24,
      "files": [
        "backend/routers/twins.py:42",
        "backend/routers/sources.py:15",
        "backend/routers/conversations.py:8",
        "backend/routers/messages.py:20",
        "backend/routers/escalations.py:12",
        "backend/routers/verified_qna.py:35"
      ],
      "required_imports": [
        "from fastapi import Depends, HTTPException",
        "from modules.auth_guard import get_current_user, verify_owner"
      ],
      "rationale": "Prevents 'missing multi-tenant filter' regression (AGENTS.md #10). Always use dependency injection for auth checks.",
      "related_patterns": ["multi_tenant_filter", "dependency_injection", "error_handling_401_403"],
      "anti_patterns": [
        "Manual JWT parsing in route body",
        "Hardcoded admin checks",
        "Missing verify_owner call"
      ],
      "testing": "Test with valid user_id, invalid user_id, and user without access"
    },
    {
      "id": "multi_tenant_filter",
      "name": "Multi-Tenant Query Filter",
      "category": "database",
      "language": "python",
      "description": "Critical pattern: Always filter queries by tenant_id to ensure data isolation",
      "code": "result = supabase.table('twins').select('*')\n    .eq('tenant_id', user['tenant_id']).execute()",
      "usage_count": 31,
      "files": ["backend/routers/twins.py:58"],
      "required_imports": ["from modules.observability import supabase"],
      "rationale": "CRITICAL for data isolation and security. Missing filter = data leak",
      "common_mistakes": [
        "Forgetting tenant_id filter entirely",
        "Using owner_id instead of tenant_id",
        "Not applying filter to joins",
        "Filtering by wrong column (e.g., user_id)"
      ],
      "correct_column": "tenant_id (maps to auth.uid())",
      "incorrect_columns": ["owner_id", "user_id", "created_by"],
      "note": "schema reference: twins table has tenant_id UUID NOT NULL column"
    },
    {
      "id": "supabase_client_singleton",
      "name": "Supabase Client Singleton Pattern",
      "category": "client_management",
      "language": "python",
      "description": "Use centralized Supabase client instead of creating new instances",
      "code": "from modules.observability import supabase",
      "usage_count": 45,
      "files": [
        "backend/modules/retrieval.py",
        "backend/modules/answering.py",
        "backend/routers/*.py"
      ],
      "rationale": "CRITICAL (AGENTS.md Do-Not-Touch #4). Duplicate clients cause connection pooling issues and auth token mismatches",
      "anti_pattern": "from supabase import create_client; supabase = create_client(...)",
      "why_singleton": "Ensures token refresh consistency, connection pooling, and resource efficiency",
      "migration_guide": "Replace all `create_client()` with import from `modules.observability`"
    },
    {
      "id": "jwt_validation_with_audience",
      "name": "JWT Validation with Audience Check",
      "category": "security",
      "language": "python",
      "description": "Validate JWT tokens with correct audience claim",
      "code": "payload = jwt.decode(\n    token,\n    JWT_SECRET,\n    algorithms=['HS256'],\n    audience='authenticated'  # CRITICAL: must match Supabase setup\n)",
      "usage_count": 8,
      "files": ["backend/modules/auth_guard.py:42"],
      "rationale": "CRITICAL. Wrong audience = 401 errors. Correct audience = 'authenticated'",
      "common_mistakes": [
        "Omitting audience parameter",
        "Using wrong audience value",
        "Not matching Supabase JWT_SECRET"
      ],
      "required_env": "JWT_SECRET from Supabase Dashboard → Settings → API",
      "testing": "Test with token from Supabase auth, verify audience claim"
    },
    {
      "id": "error_handling_401_403",
      "name": "HTTP Error Handling Pattern (401/403/404)",
      "category": "error_handling",
      "language": "python",
      "description": "Standardized error responses for auth and access control",
      "code": "# 401 Unauthorized (missing/invalid JWT)\nif not token:\n    raise HTTPException(status_code=401, detail='Missing authentication token')\n\n# 403 Forbidden (access denied)\nif not verify_owner(user, twin_id):\n    raise HTTPException(status_code=403, detail='Access denied: not resource owner')\n\n# 404 Not Found or Access Denied (don't leak existence)\nif not found or not owned:\n    raise HTTPException(status_code=404, detail='Twin not found or access denied')",
      "usage_count": 19,
      "files": ["backend/routers/twins.py", "backend/routers/sources.py"],
      "status_codes": {
        "401": "Missing/invalid JWT (authentication failure)",
        "403": "Access denied (authorization failure)",
        "404": "Resource not found OR access denied (don't leak existence)",
        "500": "Server error (unexpected exception)"
      },
      "rationale": "Clear error status codes prevent information leakage and aid debugging",
      "anti_patterns": [
        "Returning 404 for auth failures (confusing)",
        "Returning 500 for permission errors (wrong HTTP semantics)",
        "Revealing resource existence via error message"
      ]
    },
    {
      "id": "rls_policy_creation",
      "name": "Row Level Security (RLS) Policy Pattern",
      "category": "database",
      "language": "sql",
      "description": "Template for creating RLS policies on new tables",
      "code": "-- Enable RLS on table\nALTER TABLE my_table ENABLE ROW LEVEL SECURITY;\n\n-- Policy: Users see only their tenant's records\nCREATE POLICY 'users_see_own_records'\n    ON my_table FOR SELECT\n    USING (tenant_id = auth.uid());\n\n-- Policy: Users can insert only for their tenant\nCREATE POLICY 'users_insert_own_records'\n    ON my_table FOR INSERT\n    WITH CHECK (tenant_id = auth.uid());",
      "usage_count": 15,
      "files": [
        "backend/database/migrations/*.sql",
        "backend/database/schema/supabase_schema.sql"
      ],
      "rationale": "CRITICAL for multi-tenant isolation. Every table needs RLS.",
      "checklist": [
        "[ ] Is RLS enabled on the table? (ALTER TABLE ... ENABLE ROW LEVEL SECURITY)",
        "[ ] Are SELECT policies defined? (who can read)",
        "[ ] Are INSERT policies defined? (who can create)",
        "[ ] Are UPDATE policies defined? (who can modify)",
        "[ ] Are DELETE policies defined? (who can remove)",
        "[ ] Do all policies use tenant_id filter?",
        "[ ] Tested in Supabase SQL Editor?"
      ],
      "common_mistakes": [
        "Enabling RLS but forgetting policies (locks out all access)",
        "Using user_id instead of tenant_id",
        "Not testing policies before deployment",
        "Missing RLS on sensitive tables (e.g., verified_qna)"
      ]
    },
    {
      "id": "database_migration_template",
      "name": "Database Migration Template",
      "category": "database",
      "language": "sql",
      "description": "Standard template for creating new migrations",
      "code": "-- Migration: descriptive_migration_name.sql\n-- Purpose: Brief description of what this migration accomplishes\n-- Date: YYYY-MM-DD\n-- Author: AI Agent\n\n-- Create table\nCREATE TABLE IF NOT EXISTS my_table (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    twin_id UUID NOT NULL REFERENCES twins(id) ON DELETE CASCADE,\n    tenant_id UUID NOT NULL,\n    name TEXT NOT NULL,\n    data JSONB,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n-- Enable RLS\nALTER TABLE my_table ENABLE ROW LEVEL SECURITY;\n\n-- RLS Policies\nCREATE POLICY 'users_see_own_records'\n    ON my_table FOR SELECT\n    USING (tenant_id = auth.uid());\n\nCREATE POLICY 'users_insert_own_records'\n    ON my_table FOR INSERT\n    WITH CHECK (tenant_id = auth.uid());\n\n-- Indexes for performance\nCREATE INDEX IF NOT EXISTS idx_my_table_twin_id ON my_table(twin_id);\nCREATE INDEX IF NOT EXISTS idx_my_table_tenant_id ON my_table(tenant_id);",
      "usage_count": 7,
      "files": [
        "backend/database/migrations/*.sql"
      ],
      "required_steps": [
        "1. Test migration in Supabase SQL Editor first",
        "2. Reload PostgREST schema cache (Supabase → Settings → API)",
        "3. Create migration file in backend/database/migrations/",
        "4. Apply via backend/migrations/ module"
      ],
      "rationale": "Standardized migrations prevent schema inconsistencies and data corruption",
      "anti_patterns": [
        "Modifying tables directly in Supabase UI (not tracked in git)",
        "Missing IF NOT EXISTS (idempotency)",
        "Forgetting RLS and policies",
        "Not including indexes on FK columns"
      ]
    },
    {
      "id": "verified_qna_retrieval_priority",
      "name": "Verified QnA Retrieval Priority Pattern",
      "category": "retrieval",
      "language": "python",
      "description": "Correct query priority for RAG-lite system: Verified QnA → Vectors → Tools",
      "code": "# 1. Check verified_qna first (canonical answers, highest priority)\nverified = supabase.table('verified_qna')\n    .select('*')\n    .eq('twin_id', twin_id)\n    .eq('is_active', True)\n    .execute()\n\nif verified.data:\n    return verified.data[0]  # Return immediately\n\n# 2. Fall back to vector embeddings (semantic search)\nembeddings = pinecone_index.query(\n    query_embedding,\n    filter={'twin_id': twin_id},\n    top_k=3\n)\n\nif embeddings:\n    return synthesize_answer_from_embeddings(embeddings)\n\n# 3. Last resort: External tools\ntool_results = await call_tool(query, twin_id)\nreturn tool_results if tool_results else 'I don\\'t know'",
      "usage_count": 3,
      "files": ["backend/modules/retrieval.py:85"],
      "why_order_matters": "Ensures canonical answers NEVER regress. Verified QnA is ground truth.",
      "rationale": "CRITICAL for compound engineering. Each escalation creates a verified answer that becomes system knowledge.",
      "common_mistakes": [
        "Searching vectors before verified_qna",
        "Not checking is_active flag",
        "Missing twin_id filter on any search"
      ]
    },
    {
      "id": "dependency_injection_pattern",
      "name": "FastAPI Dependency Injection Pattern",
      "category": "architecture",
      "language": "python",
      "description": "Use FastAPI Depends() for auth, validation, and resource loading",
      "code": "@router.get('/resource/{resource_id}')\nasync def get_resource(\n    resource_id: str,\n    user: dict = Depends(get_current_user),\n    db_resource = Depends(load_resource)\n):\n    # user and db_resource are automatically injected\n    # Dependencies run in order\n    verify_owner(user, db_resource['owner_id'])\n    return db_resource",
      "usage_count": 28,
      "files": [
        "backend/routers/*.py"
      ],
      "why_this_pattern": "Separates concerns: auth, validation, resource loading are all explicit",
      "common_mistakes": [
        "Manual parsing of Authorization header",
        "Loading resources inside route logic (not reusable)",
        "Not specifying dependencies in function signature"
      ]
    },
    {
      "id": "langfuse_session_tracking",
      "name": "LangFuse Session Tracking Pattern",
      "category": "observability",
      "language": "python",
      "description": "Track conversations and messages with LangFuse for observability",
      "code": "from modules.observability import get_langfuse_client\n\nlangfuse = get_langfuse_client()\n\n# Create session for conversation\nsession = langfuse.session(\n    user_id=user_id,\n    metadata={'twin_id': twin_id}\n)\n\n# Log messages\nsession.message(\n    name='agent_response',\n    input=user_query,\n    output=agent_answer,\n    metadata={'confidence_score': 0.95}\n)",
      "usage_count": 5,
      "files": ["backend/modules/observability.py"],
      "rationale": "Critical for debugging agent behavior and understanding failure patterns",
      "benefits": [
        "Full conversation audit trail",
        "Performance monitoring per user/twin",
        "Cost tracking per operation",
        "User behavior analytics"
      ]
    },
    {
      "id": "openai_client_initialization",
      "name": "OpenAI Client Centralized Initialization",
      "category": "client_management",
      "language": "python",
      "description": "Use centralized OpenAI client from modules/clients.py",
      "code": "from modules.clients import get_openai_client\n\nopenai_client = get_openai_client()\n\nresponse = openai_client.chat.completions.create(\n    model='gpt-4o',\n    messages=messages,\n    temperature=0.7\n)",
      "usage_count": 18,
      "files": [
        "backend/modules/clients.py",
        "backend/modules/answering.py"
      ],
      "rationale": "Centralized initialization enables API key rotation, rate limiting, and cost tracking",
      "anti_pattern": "from openai import OpenAI; client = OpenAI() (in each module)"
    },
    {
      "id": "pinecone_metadata_filtering",
      "name": "Pinecone Metadata Filtering Pattern",
      "category": "retrieval",
      "language": "python",
      "description": "Always filter Pinecone queries by twin_id metadata",
      "code": "results = index.query(\n    vector=query_embedding,\n    filter={'twin_id': twin_id},  # CRITICAL: Must include\n    top_k=5,\n    include_metadata=True\n)",
      "usage_count": 12,
      "files": ["backend/modules/retrieval.py"],
      "why_critical": "Without twin_id filter, could retrieve answers from other twins (data leak)",
      "pinecone_config": "Dimension: 3072 (text-embedding-3-large), Metric: Cosine",
      "anti_patterns": [
        "Querying Pinecone without filter (gets all twins)",
        "Using wrong metadata key",
        "Not validating filter was applied"
      ]
    },
    {
      "id": "response_validation_pydantic",
      "name": "Pydantic Response Validation Pattern",
      "category": "validation",
      "language": "python",
      "description": "Use Pydantic models for request/response validation",
      "code": "from pydantic import BaseModel, Field\n\nclass MessageCreateRequest(BaseModel):\n    twin_id: str = Field(..., description='Twin ID')\n    conversation_id: str = Field(..., description='Conversation ID')\n    content: str = Field(..., min_length=1, max_length=5000)\n    confidence_required: Optional[float] = Field(default=0.7, ge=0.0, le=1.0)\n\n@router.post('/messages')\nasync def create_message(req: MessageCreateRequest):\n    # req is automatically validated\n    return {'id': create_message_in_db(req)}", 
      "usage_count": 22,
      "files": ["backend/modules/schemas.py"],
      "benefits": [
        "Automatic type checking",
        "Validation error messages",
        "OpenAPI documentation",
        "IDE auto-complete"
      ]
    },
    {
      "id": "escalation_workflow",
      "name": "Escalation Workflow Pattern",
      "category": "domain_logic",
      "language": "python",
      "description": "Standard flow for escalating low-confidence answers to humans",
      "code": "# If confidence < threshold, escalate\nif confidence_score < CONFIDENCE_THRESHOLD:\n    escalation = supabase.table('escalations').insert({\n        'message_id': message_id,\n        'status': 'pending',\n        'created_at': NOW()\n    }).execute()\n    \n    return {\n        'answer': 'I\\'m not sure. A human expert will review this.',\n        'status': 'escalated',\n        'escalation_id': escalation.data[0]['id']\n    }\nelse:\n    return {'answer': answer, 'status': 'answered'}",
      "usage_count": 8,
      "files": ["backend/modules/answering.py"],
      "rationale": "Implements compound engineering: uncertain answers become verified answers",
      "key_metric": "CONFIDENCE_THRESHOLD (typically 0.7-0.85)"
    },
    {
      "id": "middleware_order_critical",
      "name": "FastAPI Middleware Order (CRITICAL)",
      "category": "architecture",
      "language": "python",
      "description": "Correct middleware order in main.py prevents auth bypasses",
      "code": "# Correct order in main.py:\napp = FastAPI()\n\n# 1. CORS first (allows cross-origin requests)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=allowed_origins,\n    allow_credentials=True,\n    allow_methods=['*'],\n    allow_headers=['*'],\n)\n\n# 2. Auth middleware next (validates JWT)\napp.add_middleware(\n    AuthMiddleware,  # Custom middleware\n    jwt_secret=JWT_SECRET\n)\n\n# 3. Then route inclusion\napp.include_router(auth_router)\napp.include_router(twins_router)",
      "usage_count": 1,
      "files": ["backend/main.py"],
      "why_order_matters": "CORS before Auth allows preflight requests. Auth before routes validates all endpoints.",
      "do_not_touch": "AGENTS.md explicitly forbids reordering middleware in main.py",
      "anti_pattern": "Putting Auth middleware before CORS (breaks CORS preflight)"
    },
    {
      "id": "access_group_filtering",
      "name": "Access Group Filtering Pattern",
      "category": "authorization",
      "language": "python",
      "description": "Filter content based on user's group membership (Phase 5)",
      "code": "# Get user's groups\ngroups = supabase.table('group_memberships')\n    .select('group_id')\n    .eq('user_id', user_id)\n    .execute()\n\n# Filter content by group permissions\ncontent = supabase.table('content_permissions')\n    .select('content_id')\n    .in_('group_id', groups.data)\n    .eq('permission_type', 'read')\n    .execute()",
      "usage_count": 6,
      "files": ["backend/routers/access_groups.py"],
      "rationale": "Segment twin's knowledge by audience (e.g., public, team, private)"
    },
    {
      "id": "api_key_domain_validation",
      "name": "API Key + Domain Validation Pattern",
      "category": "security",
      "language": "python",
      "description": "Validate API key ownership and domain allowlist (Phase 7)",
      "code": "# Validate API key\napi_key_record = supabase.table('twin_api_keys')\n    .select('*')\n    .eq('key', api_key)\n    .single()\n    .execute()\n\n# Validate domain\nif 'domain_allowlist' in api_key_record.data:\n    if request.origin not in api_key_record.data['domain_allowlist']:\n        raise HTTPException(status_code=403, detail='Domain not allowed')",
      "usage_count": 4,
      "files": ["backend/routers/api_keys.py"]
    },
    {
      "id": "trigger_and_actions_pattern",
      "name": "Action Trigger & Approval Pattern",
      "category": "domain_logic",
      "language": "python",
      "description": "AI drafts actions, humans approve before execution (Phase 8)",
      "code": "# 1. AI drafts action\naction_draft = supabase.table('action_drafts').insert({\n    'twin_id': twin_id,\n    'trigger_id': trigger_id,\n    'proposed_action': json.dumps(action_spec),\n    'status': 'pending_approval'\n}).execute()\n\n# 2. Human reviews and approves\nif human_approved:\n    # Execute action\n    execution_result = await execute_action(action_spec)\n    \n    # Log execution\n    supabase.table('action_executions').insert({\n        'draft_id': action_draft.data[0]['id'],\n        'result': json.dumps(execution_result),\n        'status': 'completed'\n    }).execute()",
      "usage_count": 3,
      "files": ["backend/modules/actions.py"]
    },
    {
      "id": "specialization_manifest_resolution",
      "name": "Specialization Manifest Resolution Pattern",
      "category": "specializations",
      "language": "python",
      "description": "Resolve specialization at runtime based on twin settings",
      "code": "# Get twin's specialization\ntwin = supabase.table('twins').select('specialization_id').eq('id', twin_id).single().execute()\n\n# Load specialization manifest\nfrom backend.modules.specializations.registry import get_specialization_manifest\nmanifest = get_specialization_manifest(twin.data['specialization_id'])\n\n# Use specialization in prompts, UI, knowledge structure\nprompt = manifest['prompts']['system_prompt']\nui_config = manifest['ui']['clusters']\nontology = manifest['ontology']['base_pack']",
      "usage_count": 5,
      "files": ["backend/routers/specializations.py"],
      "rationale": "Enables multi-variant twins (VC Brain, Legal Brain) without code duplication"
    }
  ]
}
